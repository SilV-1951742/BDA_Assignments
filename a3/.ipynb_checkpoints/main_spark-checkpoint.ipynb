{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb7b45eb-b95e-4bed-b429-10717c3a0512",
   "metadata": {},
   "source": [
    "# Setup spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7764bccb-ae89-431d-8b0a-44690d69d75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] =\"--conf spark.driver.memory=2g  pyspark-shell\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import flatten\n",
    "from pyspark.sql.types import (StructType, StructField, StringType, \n",
    "                                FloatType, DateType, IntegerType, ArrayType)\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"BDA assignment\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b534ea9a-b7cf-4971-9330-6cb615863303",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bbd6460-830a-445d-863b-b87edb4b0a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple, Final, List\n",
    "#from lxml import etree\n",
    "import xml.etree.ElementTree as ET\n",
    "from itertools import islice, chain, combinations\n",
    "import argparse\n",
    "import traceback\n",
    "import bleach\n",
    "import html\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import pr\n",
    "import string\n",
    "import random\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6aed4f-9be9-4a14-a996-078adae3e54f",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d055241-e20d-43b1-8406-d412b5f34cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHINGLE_SIZE: Final = 5\n",
    "SAMPLES: Final = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57f90724-7f77-4267-bd27-723fdef44ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class comment_tuple(NamedTuple):\n",
    "    id: int\n",
    "    #owner_id: int\n",
    "    post_type: int\n",
    "    score: int\n",
    "    text: str\n",
    "\n",
    "class shingle_set(NamedTuple):\n",
    "    id: int\n",
    "    shingles: frozenset[tuple]\n",
    "\n",
    "class similarity(NamedTuple):\n",
    "    id_set1: int\n",
    "    id_set2: int\n",
    "    similarity: float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed988ef-bf90-4ec9-a288-c32a0441df13",
   "metadata": {},
   "source": [
    "# Read and clean XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc472be3-e7df-4983-ad8d-734155857e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_schema():\n",
    "    \"\"\"\n",
    "    Define the schema for the DataFrame\n",
    "    \"\"\"\n",
    "    schema_list = []\n",
    "    schema_list.append(StructField(\"Id\", IntegerType(), True))\n",
    "    #schema_list.append(StructField(\"PostTypeId\", IntegerType(), True))\n",
    "    #schema_list.append(StructField(\"Score\", IntegerType(), True))\n",
    "    schema_list.append(StructField(\"Body\", StringType(), True))\n",
    "    \n",
    "    return StructType(schema_list)\n",
    "\n",
    "def parse_post(rdd):\n",
    "    results = []\n",
    "    root = ET.fromstring(rdd[0])\n",
    "\n",
    "    for elem in root.findall('row'):\n",
    "        rec = []\n",
    "        #print(\"Found row\")\n",
    "        assert elem.text is None, \"The row wasn't empty\"\n",
    "        rec.append(int(elem.attrib[\"Id\"]))\n",
    "        #int(elem.attrib[\"OwnerUserId\"]),\n",
    "        #rec.append(int(elem.attrib[\"PostTypeId\"])),\n",
    "        #rec.append(int(elem.attrib[\"Score\"])),\n",
    "        rec.append(bleach.clean(elem.attrib[\"Body\"], strip=True))\n",
    "        #rec.append(elem.attrib[\"Body\"])\n",
    "\n",
    "        #elem.clear()\n",
    "        #while elem.getprevious() is not None:\n",
    "        #    del elem.getparent()[0]\n",
    "        results.append(rec)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de9e592e-7f1e-40a0-8a94-95a8a8018038",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"cstheory_posts.bakxml\"\n",
    "chunksize = 1024\n",
    "\n",
    "file_rdd = spark.read.text(filename, wholetext=True).rdd\n",
    "dataset = file_rdd.flatMap(parse_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d1b1d30-61e5-488f-a09e-76acb8969874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| Id|                Body|\n",
      "+---+--------------------+\n",
      "|  2|I have a dataset ...|\n",
      "|  3|A particular prog...|\n",
      "|  4|What is the follo...|\n",
      "|  5|Can the divide an...|\n",
      "|  6|Is anyone aware o...|\n",
      "|  7|In general, the q...|\n",
      "|  8|If I understand t...|\n",
      "|  9|<a href=\"http://w...|\n",
      "| 10|There was recentl...|\n",
      "| 11|Functional progra...|\n",
      "| 12|I took a class on...|\n",
      "| 13|It's possible tha...|\n",
      "| 14|Other than going ...|\n",
      "| 15|[This question ha...|\n",
      "| 16|See the <a href=\"...|\n",
      "| 17|it is often said ...|\n",
      "| 18|In one word: No.\n",
      "...|\n",
      "| 19|In short, I would...|\n",
      "| 20|It's easy to prov...|\n",
      "| 21|Any &quot;cutting...|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.persist()\n",
    "schema = set_schema()\n",
    "df_ds = dataset.toDF(schema)\n",
    "df_ds.show()\n",
    "\n",
    "#df_posts = records_rdd.toDF(schema)\n",
    "#coll = records_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ed4fe3-7297-4445-8ce2-32be93b42e1c",
   "metadata": {},
   "source": [
    "# Shingling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e3fecd3-7b72-490d-b4ab-b1c8c4920cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class shingler:\n",
    "    \"\"\"\n",
    "    Class that contain a tokenizer and stopwords to make shingling easier.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.stopwords = set(stopwords.words('english'))\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        return True\n",
    "\n",
    "    def tokenize(self, text: str) -> List[str]:\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        # text_nop = text.split()\n",
    "        text_nop = word_tokenize(text)\n",
    "        filtered_words = []\n",
    "\n",
    "        for word in text_nop:\n",
    "            if word not in self.stopwords:\n",
    "                filtered_words.append(word.lower())\n",
    "        \n",
    "        return filtered_words\n",
    "\n",
    "    #def create_shingle(self, input_comment: comment_tuple, shingle_size: int) -> frozenset[tuple]:\n",
    "    #    tokens = self.tokenize(input_comment.text)\n",
    "    #    comment_length = len(tokens)\n",
    "    #    shingles =  frozenset(tuple(tokens[i:(i + shingle_size)]) for i in range(comment_length - shingle_size + 1))\n",
    "    \n",
    "    def create_shingle(self, post: str, shingle_size: int) -> list[list]:\n",
    "        tokens = self.tokenize(post)\n",
    "        comment_length = len(tokens)\n",
    "        shingle_set = frozenset(tuple(tokens[i:(i + shingle_size)]) for i in range(comment_length - shingle_size + 1))\n",
    "        shingle_list = list(shingle_set)\n",
    "        #for elem in shingle_list:\n",
    "        #    elem.sort()\n",
    "        shingle_list.sort()\n",
    "        return list(shingle_set)\n",
    "        \n",
    "\n",
    "def shingle_map(row):\n",
    "    ds_shingler = shingler()\n",
    "    return (row[0], ds_shingler.create_shingle(row[1], SHINGLE_SIZE)\n",
    ")\n",
    "\n",
    "def set_shingle_schema():\n",
    "    \"\"\"\n",
    "    Define the schema for the DataFrame\n",
    "    \"\"\"\n",
    "    schema_list = []\n",
    "    schema_list.append(StructField(\"Id\", IntegerType(), True))\n",
    "    #schema_list.append(StructField(\"PostTypeId\", IntegerType(), True))\n",
    "    #schema_list.append(StructField(\"Score\", IntegerType(), True))\n",
    "    schema_list.append(StructField(\"Shingles\", ArrayType(ArrayType(StringType()), True)))\n",
    "    return StructType(schema_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "855eb6f2-07ef-4ef9-b1ba-f8d3d0a9209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = set_shingle_schema()\n",
    "shingle_rdd = dataset.map(shingle_map)\n",
    "#df_shingle = shingle_rdd.toDF(schema)\n",
    "#df_shingle.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b363a0e8-480f-4bc0-9167-1b58be6e6c80",
   "metadata": {},
   "source": [
    "# MinHashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3799fdf-d96c-4f41-87fd-f40c6353a4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2098660572, 74013022, 2675907171, 2481944613, 2289028529, 846582864, 1024003631, 3457496236, 958218556, 2872479854, 1385329197, 2720560315, 2596604670, 4118717270, 3831528778, 4184700433, 130382780, 4221132295, 2492231677, 1349853675, 2674011478, 4230155413, 522369175, 1349933754, 2597169981, 1045439184, 3199517916, 3020468163, 618450142, 3282454786, 4061764145, 3477766529, 3055070885, 204747729, 834378094, 4046990333, 2141660100, 2118590568, 3537961224, 168082228, 652073352, 1284401985, 2826423363, 1325707607, 3731067674, 723716237, 3333080471, 2787841228, 2113795590, 3230829213]\n",
      "[[1843969928, 746019385, 2309594694, 2229839123, 489336389, 779150137, 1446103079, 889348879, 3745936412, 4281307413, 2173665908, 1717438567, 23839969, 2145022294, 1052302893, 1118678081, 1295195691, 3851408124, 3928788718, 2370966349, 561561790, 1051546482, 4224882136, 4206633849, 1329396735, 1801554849, 1138195103, 3123692201, 1122989246, 1270364612, 1593839649, 1463959047, 4229718824, 1709163888, 33163415, 2667737317, 2446567315, 4184687507, 3396502067, 483813678, 2220062805, 290402151, 576718488, 2834691631, 2746963148, 1838059277, 3070124528, 885776293, 1650043432, 3582686598], [220792127, 2535197382, 1699971710, 1898865050, 3798071317, 2827338235, 435208719, 1570192009, 2360615333, 515231859, 643500, 4187339056, 509908782, 486802097, 3677215785, 2921827920, 3237468089, 3427794385, 4032002655, 4093886240, 2687035724, 3077734642, 1170835917, 432938307, 2306967322, 2141534378, 2906718316, 1574298930, 4232243766, 240355277, 3647978042, 2451964704, 3514275296, 2490192022, 1350263172, 1011477998, 1728226503, 2593311830, 2348203625, 2090761938, 2237486929, 2969854285, 3729324258, 2729987853, 2824894019, 4163387808, 3551421043, 4153788824, 2068844359, 3459047483]]\n"
     ]
    }
   ],
   "source": [
    "# Transform posts to characteristic matrix\n",
    "# Make feature set matrix\n",
    "# Minhash\n",
    "# Make Minhash Matrix\n",
    "# LSH\n",
    "import random\n",
    "SIGNATURE_SIZE: Final = 50\n",
    "HASH_PRIME: Final = (1 << 31) - 1\n",
    "MAX_HASH: Final = (1 << 32)\n",
    "    #sys.maxsize\n",
    "HASH_RANGE: Final = (1<< 32)\n",
    "    #sys.maxsize\n",
    "SEED: Final = 193120\n",
    "\n",
    "generator = np.random.RandomState(SEED)\n",
    "salts = [generator.randint(1, MAX_HASH) for _ in range(SIGNATURE_SIZE)]\n",
    "#permutations = [generator.randint(1, HASH_PRIME) for _ in range(SIGNATURE_SIZE)]\n",
    "\n",
    "permutations = [[generator.randint(1, MAX_HASH) for _ in range(SIGNATURE_SIZE)],\n",
    "                [generator.randint(0, MAX_HASH) for _ in range(SIGNATURE_SIZE)]]\n",
    "\n",
    "print(salts)\n",
    "print(permutations)\n",
    "\n",
    "def hash_func(data, p1, p2):\n",
    "    \n",
    "    return int.from_bytes(hashlib.md5(int.to_bytes(salt, 8, byteorder=\"big\") + json.dumps(data).encode()).digest()[:8], byteorder=\"big\")\n",
    "    \n",
    "def min_hasher(row):\n",
    "    sig = np.full((SIGNATURE_SIZE), MAX_HASH)\n",
    "    for shingle in row[1]:\n",
    "        for i in range(SIGNATURE_SIZE):\n",
    "            a = permutations[0][i]\n",
    "            b = permutations[1][i]\n",
    "            hash_val = (a * hash(shingle) + b) % HASH_PRIME\n",
    "            #hash_func(tuple(shingle), salts[i]) % HASH_PRIME\n",
    "            sig[i] = min(hash_val, sig[i])\n",
    "    return (row[0], sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4314e1cc-f0b4-4631-824c-ad0bbfc48fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253594894\n"
     ]
    }
   ],
   "source": [
    "a = permutations[0][1]\n",
    "b = permutations[1][1]\n",
    "\n",
    "hash_val = (a * hash(tuple([\"text\", \"word\", \"shingle\", \"advanced\"]))+ b) % HASH_PRIME\n",
    "print(hash_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "863a39cf-392b-4310-9950-92bb58df1890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, array([  2642774,  34835332,  73782674,  21266037,  43363373,  63375525,\n",
      "        64780483, 221547471,  36363255,  51638969,  76963240,  51866191,\n",
      "        67658569,  22051358,  10384782,  11787093,  11974757,   4601448,\n",
      "        48843986,  91175009,  39248163,  13055715, 182395884,  96883907,\n",
      "        28649451,  65482425,  26380695,  40817098,  58945925,  24172262,\n",
      "        41336337,   2597183,  86945717,  20692157, 100898042,  60416914,\n",
      "        50895349,  95380440,  17940440,  40390223,  96414874,  21914682,\n",
      "         8816484,     42951,  39669483,  70060900, 111568449,  38701334,\n",
      "        21925107, 111343460]))\n",
      "(3, array([   864466,  52734412,  39592123,  28720135,  53387950,  50144848,\n",
      "        23262955,  76419385,  81890689,  29974913,  31177450,  89574785,\n",
      "        91512184,   5498854,  10541739,   5555579,   4679775,  18672544,\n",
      "       124799783,  15602970,  41537678,  97334216,   2753034,  29277312,\n",
      "        23256660,  43841607,   3479836,  41146054,  41769611,  38661388,\n",
      "        61262458,  31247793,  17032667,  16350620,  52923591,  55880226,\n",
      "         8935963,  13799213,  21380091,  29679109,  87419111,  20416815,\n",
      "         2936891,  10120481,  14955994,  42417179,  18447023,   7361197,\n",
      "         2731450,  16833601]))\n",
      "(4, array([14188986, 26244885, 37459795,  5406762,  9104197, 19340472,\n",
      "       37082115,  9516671, 13332433, 10657283,  1648160, 13856618,\n",
      "       96481883,  8543377,  4705409, 37044790, 20475528,  8688185,\n",
      "       13957040,  9670896,  7558827,  3250292, 15773141, 14108162,\n",
      "        8007557,  8592190,   214253,  8347153, 61416606, 64416342,\n",
      "       27622174,  4498125,  2944122, 29922575, 12862002, 30022932,\n",
      "          66396, 52252545, 14682709,  5112252,  1028208, 22833746,\n",
      "       12417098,  5942438,  2931782,  4043694, 17853206, 32989626,\n",
      "       23469295,  2155434]))\n"
     ]
    }
   ],
   "source": [
    "hash_rdd = shingle_rdd.map(min_hasher)\n",
    "\n",
    "for elem in hash_rdd.take(3):\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d745c9-7084-4756-8d7d-993612a4daf3",
   "metadata": {},
   "source": [
    "# LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a0a2172-ea98-45a5-bd56-51aef933432c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bands: 10, rows 5, threshold 0.6309573444801932\n",
      "[(2, 0), 2642774]\n",
      "[(2, 1), 34835332]\n",
      "[(2, 2), 73782674]\n",
      "[(2, 3), 21266037]\n",
      "[(2, 4), 43363373]\n",
      "[(2, 5), 63375525]\n",
      "[(2, 6), 64780483]\n",
      "[(2, 7), 221547471]\n",
      "[(2, 8), 36363255]\n",
      "[(2, 9), 51638969]\n",
      "[(2, 0), 76963240]\n",
      "[(2, 1), 51866191]\n",
      "[(2, 2), 67658569]\n",
      "[(2, 3), 22051358]\n",
      "[(2, 4), 10384782]\n",
      "[(2, 5), 11787093]\n",
      "[(2, 6), 11974757]\n",
      "[(2, 7), 4601448]\n",
      "[(2, 8), 48843986]\n",
      "[(2, 9), 91175009]\n",
      "[(2, 0), 39248163]\n",
      "[(2, 1), 13055715]\n",
      "[(2, 2), 182395884]\n",
      "[(2, 3), 96883907]\n",
      "[(2, 4), 28649451]\n",
      "[(2, 5), 65482425]\n",
      "[(2, 6), 26380695]\n",
      "[(2, 7), 40817098]\n",
      "[(2, 8), 58945925]\n",
      "[(2, 9), 24172262]\n",
      "[(2, 0), 41336337]\n",
      "[(2, 1), 2597183]\n",
      "[(2, 2), 86945717]\n",
      "[(2, 3), 20692157]\n",
      "[(2, 4), 100898042]\n",
      "[(2, 5), 60416914]\n",
      "[(2, 6), 50895349]\n",
      "[(2, 7), 95380440]\n",
      "[(2, 8), 17940440]\n",
      "[(2, 9), 40390223]\n",
      "[(2, 0), 96414874]\n",
      "[(2, 1), 21914682]\n",
      "[(2, 2), 8816484]\n",
      "[(2, 3), 42951]\n",
      "[(2, 4), 39669483]\n",
      "[(2, 5), 70060900]\n",
      "[(2, 6), 111568449]\n",
      "[(2, 7), 38701334]\n",
      "[(2, 8), 21925107]\n",
      "[(2, 9), 111343460]\n",
      "[(3, 0), 864466]\n"
     ]
    }
   ],
   "source": [
    "BANDS: Final = 10\n",
    "ROWS: Final = 5\n",
    "THRESHOLD: Final = (1/BANDS) ** (1/ROWS)\n",
    "print(f\"Bands: {BANDS}, rows {ROWS}, threshold {THRESHOLD}\")\n",
    "\n",
    "# returns (doc, band, hash)\n",
    "hash_band_rdd = hash_rdd.flatMap(lambda x: [[(x[0], i % BANDS), hash] for i, hash in enumerate(x[1])])\n",
    "\n",
    "for elem in hash_band_rdd.take(51):\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c65ee4-7751-4764-9609-6a54b2973c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_rdd = hash_band_rdd.map(lambda x: [x[0][1], (x[0][0], x[1])]).groupByKey()\n",
    "\n",
    "for elem in bands_rdd.take(1):\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa97640b-712c-4ac2-8ee1-fed261021b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bd7b97-96fc-436f-ab3f-e5edf7d8457e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1048fc5c-8a48-4434-bd6a-92b03ccfdace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f39564-68ac-489f-8700-2b7b56ca7a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "958d9c18-eebb-4579-a6d2-987a3d16fce6",
   "metadata": {},
   "source": [
    "# Exit Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5903af5b-7751-4eef-a000-1286bdb1eeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe907960-4bf9-49a6-b964-910097827ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
